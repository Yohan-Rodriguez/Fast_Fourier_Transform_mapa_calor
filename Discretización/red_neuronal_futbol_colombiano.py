# -*- coding: utf-8 -*-
"""red_neuronal_futbol_colombiano

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rih_TVwbrPNzaeln3JNkoeo6avadtwmw

# 1) **Librerías**
"""

import os
from google.colab import drive

import numpy as np
import pandas as pd

# Habilitar mostrar todas las columnas
pd.set_option('display.max_columns', None)

# Montar Google Drive
drive.mount('/content/drive')

"""# 2) **DF Estadísticas campeonato**

## 2.1 **Dataset**
"""

# Listar archivos en una carpeta específica
path = '/content/drive/My Drive/Colab Notebooks/Algoritmos de ML/Red Neuronal Fútbol Colombiano/Jornadas'

# DataFrame base
df = pd.DataFrame()

# Iterar sobre los archivos en el directorio
for archivo in os.listdir(path):
  # Ruta de un archivo ".csv" en particular
  ruta_archivo = os.path.join(path, archivo)
  # Verificar si "ruta_archivo" es un archivo
  if os.path.isfile(ruta_archivo):
    # Verificar si el archivo es un archivo CSV
    if ruta_archivo[-3:] == 'csv':
      # Concatenar la información de los archivos ".csv"
      df = pd.concat([df, pd.read_csv(ruta_archivo, encoding='latin1', sep=',')], ignore_index=True)

# Organizar por jornada
df.sort_values(by='JOR', inplace=True)

# Setear los indices de manera continua de 0 a 189
df.reset_index(drop=True, inplace=True)

df

"""## 2.2 **DF por Jornadas** [190 partidos: 10 partidos * 19 jornadas]"""

# Extraer estadísticas del equipo local
stats_h = [ i_stat.replace('[', '').replace(']', '').replace("'", '').replace("'", '').split(', ') for i_stat in df['stats_match_H'] ]
# Extraer estadísticas del equipo visitante
stats_a = [ i_stat.replace('[', '').replace(']', '').replace("'", '').replace("'", '').split(', ') for i_stat in df['stats_match_A'] ]

# Nombres de las nuevas columnas para el "df"
names_stats = ['%_POS_BAL', 'DIS_REC', 'TAR_AMA', 'TAR_ROJ', 'FAL_REC', 'FAL_COM', 'PER_D_POS', 'REC_D_POS', 'FUE_DE_JUE', 'DIS_REC_BLO']

# Crear nuevas columnas de estadisticas por equipo en el "DataFarme"
for enu, i_name_col in enumerate(names_stats):
  # 'DIS_REC', 'TAR_AMA', 'TAR_ROJ', 'FAL_REC', 'FAL_COM', 'PER_D_POS', 'REC_D_POS', 'FUE_DE_JUE'
  if (i_name_col != 'DIS_REC_BLO') and (i_name_col != 'POS_BAL'):
    df['{}_H'.format(i_name_col)] = [ int(i_stats_h[enu]) for i_stats_h in stats_h ]
    df['{}_A'.format(i_name_col)] = [ int(i_stats_a[enu]) for i_stats_a in stats_a ]
  # 'POS_BAL'
  elif i_name_col == 'POS_BAL':
    df['{}_H'.format(i_name_col)] = [ float(i_stats_h[enu][:-1]) for i_stats_h in stats_h ]
    df['{}_A'.format(i_name_col)] = [ float(i_stats_a[enu][:-1]) for i_stats_a in stats_a ]
  # 'DIS_REC_BLO'
  else:
    df['{}_H'.format(i_name_col)] = [ int(i_stats_h[enu+2]) for i_stats_h in stats_h ]
    df['{}_A'.format(i_name_col)] = [ int(i_stats_a[enu+2]) for i_stats_a in stats_a ]

# Agreagar estadísticas de tiros al arco (SHO_TAR_x) y tiros afuera (SHO_x)
df['SHO_TAR_H'] = [int(i_sth[-3]) for i_sth in stats_a]
df['SHO_TAR_A'] = [int(i_sta[-2]) for i_sta in stats_h]
df['SHO_H'] = [int(i_sh[-3]) for i_sh in stats_h]
df['SHO_A'] = [int(i_sa[-2]) for i_sa in stats_a]

# Crear las nuevas columnas de forma vectorizada
df['H_WIN'] = np.where(df['G_H'] > df['G_A'], 1, 0)
df['A_WIN'] = np.where(df['G_H'] < df['G_A'], 1, 0)
df['DRAW'] = np.where(df['G_H'] == df['G_A'], 1, 0)

# Eliminar las columnas originales innecesarias
df.drop(columns=['stats_names', 'stats_match_H', 'stats_match_A'], inplace=True)

df

"""## 2.2 **DF Segmentando data por fechas**"""

# Se realizará el análisis a partir de la jornada "x" a la 19
num_jornadas = 15

dict_stats = {
    'NAME_TEAM': df['HOME'].sort_values().unique(),

    # 'PJ_H',	'PG_H',	'PE_H',	'PP_H'
    'PJ_H': df[df['JOR'] >= num_jornadas].groupby('HOME')['HOME'].count().values,
    'PG_H': df[df['JOR'] >= num_jornadas].groupby('HOME')['H_WIN'].sum().values,
    'PE_H': df[df['JOR'] >= num_jornadas].groupby('HOME')['DRAW'].sum().values,
    'PP_H': df[df['JOR'] >= num_jornadas].groupby('HOME')['A_WIN'].sum().values,

    'PJ_A': df[df['JOR'] >= num_jornadas].groupby('AWAY')['AWAY'].count().values,
    'PG_A': df[df['JOR'] >= num_jornadas].groupby('AWAY')['A_WIN'].sum().values,
    'PE_A': df[df['JOR'] >= num_jornadas].groupby('AWAY')['DRAW'].sum().values,
    'PP_A': df[df['JOR'] >= num_jornadas].groupby('AWAY')['H_WIN'].sum().values,

    # GF_H	GC_H
    'GF_H': df[df['JOR'] >= num_jornadas].groupby('HOME')['G_H'].sum().values,
    'GC_H': df[df['JOR'] >= num_jornadas].groupby('HOME')['G_A'].sum().values,
    'GF_A': df[df['JOR'] >= num_jornadas].groupby('AWAY')['G_A'].sum().values,
    'GC_A': df[df['JOR'] >= num_jornadas].groupby('AWAY')['G_H'].sum().values
 }

'''
Crear DataFrame temporal
'''
dfs_stats = pd.DataFrame(dict_stats)

# Calcular los puntos de local y visitante
dfs_stats['PTS_H'] = dfs_stats.apply(lambda x: x['PG_H']*3 + x['PE_H']*1, axis=1)
dfs_stats['PTS_A'] = dfs_stats.apply(lambda x: x['PG_A']*3 + x['PE_A']*1, axis=1)
dfs_stats['PTS_T'] = dfs_stats['PTS_H'] + dfs_stats['PTS_A']

dfs_stats['PJ_T'] = dfs_stats['PJ_H'] + dfs_stats['PJ_A']



def cal_porcentajes(df):
  # Porcentajes de los equipos en condición de local
  df_porcentajes = df[['NAME_TEAM', 'PJ_H',	'PG_H',	'PE_H',	'PP_H']]
  df_porcentajes['%_PG_H'] = df_porcentajes.apply(lambda x: round(x['PG_H'] * 100 / x['PJ_H'], 2), axis=1)
  df_porcentajes['%_PE_H'] = df_porcentajes.apply(lambda x: round(x['PE_H'] * 100 / x['PJ_H'], 2), axis=1)
  df_porcentajes['%_PP_H'] = df_porcentajes.apply(lambda x: round(x['PP_H'] * 100 / x['PJ_H'], 2), axis=1)

  # Porcentajes de los equipos en condición de visitante
  df_porcentajes[['PJ_A',	'PG_A',	'PE_A',	'PP_A']] = df[['PJ_A',	'PG_A',	'PE_A',	'PP_A']]
  df_porcentajes['%_PG_A'] = df_porcentajes.apply(lambda x: round(x['PG_A'] * 100 / x['PJ_A'], 2), axis=1)
  df_porcentajes['%_PE_A'] = df_porcentajes.apply(lambda x: round(x['PE_A'] * 100 / x['PJ_A'], 2), axis=1)
  df_porcentajes['%_PP_A'] = df_porcentajes.apply(lambda x: round(x['PP_A'] * 100 / x['PJ_A'], 2), axis=1)

  return df_porcentajes


# Calcular porcentajes de los partidos de local y visitante
df_porcentajes = cal_porcentajes(dfs_stats)
dfs_stats[df_porcentajes.columns.to_list()] = df_porcentajes

# Re-úbicar columnas en posiciones nuevas
columns = dfs_stats.columns.to_list()
columns_copy = columns.copy()

columns_copy.pop(-14)  # GF_H
columns_copy.pop(-13)  # GF_A
columns_copy.pop(-10)  # PTS_H
columns_copy.pop(-9)  # PTS_A
columns_copy.pop(-8)  # PTS_T
columns_copy.pop(-7)  # PJ_T
columns_copy.pop(-6)  # %_PG_H
columns_copy.pop(-5)  # %_PE_H
columns_copy.pop(-4)  # %_PP_H

columns_copy.insert(1, columns[-8]) # PTS_T
columns_copy.insert(2, columns[-7]) # PJ_T
columns_copy.insert(3, columns[-10])  # PTS_H
columns_copy.insert(8, columns[-14])  # GF_H
columns_copy.insert(9, columns[-13])  # GF_A
columns_copy.insert(10, columns[-6])  # %_PG_H
columns_copy.insert(11, columns[-5])  # %_PE_H
columns_copy.insert(12, columns[-4])  # %_PP_H
columns_copy.insert(13, columns[-9])  # PTS_A

# DataFarme re-organizado
dfs_stats = dfs_stats.reindex(columns=columns_copy)

# Ordenar el dataframe por la columna "PTS_T" de mayor a menor
dfs_stats.sort_values(by='PTS_T', ascending=False, inplace=True)

# Re-setear índices
dfs_stats.reset_index(drop=True, inplace=True)

dfs_stats

"""# 3) **DF Heat Map's**"""

# Listar archivos en una carpeta específica
path_bin = '/content/drive/My Drive/Colab Notebooks/Algoritmos de ML/Red Neuronal Fútbol Colombiano/Archivos bin'

# DataFrame base
df_heat_maps = pd.DataFrame()

# Iterar sobre los archivos en el directorio
for archivo in os.listdir(path_bin):
  # Ruta de un archivo ".csv" en particular
  ruta_archivo = os.path.join(path_bin, archivo)
  # Verificar si "ruta_archivo" es un archivo
  if os.path.isfile(ruta_archivo):
    # Verificar si el archivo es un archivo CSV
    if ruta_archivo[-3:] == 'csv':
      # Concatenar la información de los archivos ".csv"
      df_heat_maps = pd.concat([df_heat_maps, pd.read_csv(ruta_archivo, encoding='latin1', sep=',')], ignore_index=True)

# Setear los indices de manera continua de 0 a 189
# df_heat_maps.reset_index(drop=True, inplace=True)

df_heat_maps.shape